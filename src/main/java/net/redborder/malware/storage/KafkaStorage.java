package net.redborder.malware.storage;

import kafka.producer.ProducerConfig;
import kafka.javaapi.producer.Producer;
import kafka.producer.KeyedMessage;

import org.apache.hadoop.mapreduce.lib.output.NullOutputFormat;
import org.apache.pig.StoreFunc;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.json.JSONException;
import org.json.JSONObject;
import java.util.Properties;

import java.io.IOException;

/**
 * Created by Maria on 17/03/15.
 */
public class KafkaStorage extends StoreFunc {
    private Producer<String, String> kafkaProducer;
    private String topic;
    JSONObject obj;
    String kafkaServer;


    public KafkaStorage(String topic,String kafkaServer)
    {
        this.topic=topic;
        this.kafkaServer=kafkaServer;
        kafkaProducer = null;
    }

    /*
     * Return the OutputFormat associated with StoreFuncInterface
     */
    @Override
    public org.apache.hadoop.mapreduce.OutputFormat getOutputFormat() throws IOException {
        // Â¿Decir que no se va a guardar?
        return new NullOutputFormat();
    }

    /*
     * Communicate to the storer the location where the data needs to be stored
     */
    @Override
    public void setStoreLocation(String s, org.apache.hadoop.mapreduce.Job job) throws IOException {
        // No se va a guardar en hdfs
    }

    /*
     * Initialize StoreFuncInterface to write data.
     */
    @Override
    public void prepareToWrite(org.apache.hadoop.mapreduce.RecordWriter recordWriter) throws IOException {
        // TODO: Preparar el KafkaProducer
        // We set the kafka URL and topic
        final Properties props = new Properties();
        props.put("metadata.broker.list", kafkaServer);
        props.put("serializer.class", "kafka.serializer.StringEncoder");
        kafkaProducer = new Producer<String, String>(new ProducerConfig(props));
    }

    /*
     * Write a tuple to the data store
     */
    @Override
    public void putNext(Tuple tuple) throws IOException {
        obj=new JSONObject();
        // We store a string from tuple
        for (int i=0 ; i < tuple.size() ; i++ ) {
            Object field;
            try {
                field = tuple.get(i);
            } catch (ExecException ee) {
                throw ee;
            }

            putField(field,i);
        }

        // writer.write(null, text);
        // TODO: Escribimos en kafka
        kafkaProducer.send(new KeyedMessage<String, String>(topic, obj.toString()));

        // producer.send(data);

        // Borramos el contenido
        obj=null;

    }

    // We set the field from Tuple in JSONObject
    @SuppressWarnings("unchecked")
    private void putField(Object field, int i) throws IOException {
        try {
            switch (DataType.findType(field)) {
                case DataType.NULL:
                    obj.put(String.valueOf(i), "NULL");
                    break;
                case DataType.BOOLEAN:
                    obj.put(String.valueOf(i), (boolean) field);
                    break;
                case DataType.INTEGER:
                    obj.put(String.valueOf(i), (int) field);
                    break;
                case DataType.LONG:
                    obj.put(String.valueOf(i), (long) field);
                    break;
                case DataType.FLOAT:
                    obj.put(String.valueOf(i), (float) field);
                    break;
                case DataType.DOUBLE:
                    obj.put(String.valueOf(i), (double) field);
                    break;
                case DataType.BYTEARRAY:
                    byte[] b = ((DataByteArray) field).get();
                    obj.put(String.valueOf(i), b);
                    break;
                case DataType.CHARARRAY:
                    obj.put(String.valueOf(i), (String) field);
                    break;
                case DataType.BYTE:
                    obj.put(String.valueOf(i), (byte) field);
                    break;

                case DataType.MAP:
                case DataType.TUPLE:
                case DataType.BAG:
                    throw new RuntimeException("Cannot store a non-flat tuple using KafkaStorage");
                default:
                    throw new RuntimeException("Unknown datatype " + DataType.findType(field));
            }
        } catch (JSONException e) {
            e.printStackTrace();
        }
    }
}
